 When you're creating your tables, you're going to often see this serialization to serialization thing. And so I want to make sure you fully understand it. So SCR de stands for serial serialization to serialization. This is not just for Athena, it can be for a lot of other open source libraries. And for Apache, they kind of share them because they're coming from specific projects. And specifically, the ones that Athena are using are coming from specific Apache projects. So serialization to serialization libraries for parsing data from different formats such as CSV, JSON, parquet, and work and possibly more. It is the the serialization to serialization you specify and not the domain definition language that defines the table schema because in other SQL languages, the DDL defines it but this one you have to use serialization to serialization. In other words, serialization to serialization can override the data definition language configuration that you specify in Athena when you create the table. So this is the thing that actually matters. And there are several built in serialization to serialization libraries supported by Athena. And for the most part, they're all coming from Apache, but some of them are coming from Amazon. So I'm going to get my pen tool out here so we can just kind of check them off so we understand what we're looking at here. So the first we have here is for CSV. Okay, and this one's coming from Hive. All right, and notice it says lazy simple serialization to serialization. So it's a very simple CSV parser, then there's this open CSV. And so this one's a little robust. This one's also from Hive. Then we have for parsing Avro files. I don't know I didn't list it up here. But Avro files is another common data format that's also coming from Hive. So these are from Hive. Then there's grok. I didn't look into this one too much. It's coming from glue. I'm assuming I wonder if it has anything to do with Linux grok. I don't know. But grok is, I guess kind of like grep. It's a way of parsing information. So it's it's a querying language, if you if you will, or format, then we have hive, hive for JSON. So we have that parser, then we have open x's JSON parser, and then we have another one, which is ion hive for JSON. So there's three different ones for JSON. What's different between them? I don't know, I didn't investigate, but I'm sure there's a use case for each of them. Then there's regular expressions. I see this one being used quite a bit. So this comes from hive as well. And the last example we showed that if you have orc, you just do stored as orc. And then if it's parquet, you just say stored as parquet, because those are like binary files. So there's nothing to exactly do there. But it's not just this one thing you have to specify, because each of these can can require some level of configuration. So for our regular expressions, we have to actually specify the regular expression here right here. And you'll see this thing called ser de properties, and it will vary some like most of these have this. But the but what it wants the internal will be different. There could be some additional fields here. But yeah, once you understand that it doesn't become super hard to work with Athena queries, but there you go. Okay.