 this is Andrew Brown, and we're taking a look at AWS glue jobs. And there are three types of engines that you can utilize when you create a job. The first is the Python shell engine, Ray jobs, or spark jobs. At the time of this video, Ray jobs is still in preview, so I can't make a lab on it. But I imagine that this will be functionality that will be carried forward with AWS because Ray, the Ray framework is just a really good alternative framework to spark. And it's just very efficient. For it was glue jobs, they can be created in the visual ETL, also known as the AWS glue studio, Jupyter notebooks, and the script editor, which is something that is launched within AWS. So you have those three options. ETL jobs are charged based on the number of data processing units or DPUs. And so it was glue allocates 10 DPUs to each spark job, two DPUs to each spark streaming job. And for Ray jobs, it looks like it's at six, six DPUs. The way it works is there's a combination of work type and number of workers. And that's going to determine the amount of DPUs. So those are the two things that you can play with. But yeah, there you go.