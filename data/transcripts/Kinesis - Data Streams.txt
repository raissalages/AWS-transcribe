 we're taking a look here at kinesis data streams. And so here we have our nice big pipeline as a visual, we have producers that send data to the stream, we have consumers that consume data from the stream. And we have shards, which are the compute that allows us to, for our capacity for our reads and writes. And the shards are partitions. So the idea is that as you write data, you want to write data to specific partitions, use using the partition key. But we'll get into that here momentarily notice that we have compute here just easy to instances and easy to instance on the right. The idea is that for the most part data streams is very customizable. So you can do whatever you want with it. But it was will provide code, like libraries or applications to do that. Not to say there isn't direct integration to send data to your stream and to consume data, which you use data fire hose to non programmatically work with kinesis data streams. But the most part you do have to have some good programming chops to use this thing. So data streams has two capacity modes. When I started using kinesis, it only had one which is provision, but they added an on demand node, which is a little bit confusing because it kind of competes with another product. But we'll talk about that in a moment. But for the use case, on demand makes sense when you have unpredictable workloads, because you're only paying for the capacity that you're using as opposed to a steady guarantee of capacity. Whereas provision you have, it's more suited for predictable workloads. For on demand and automatically scales for provision, you're using customer managed shards. So you have to specify the amount of shards that you're going to need. For billing on demand is based on the volume of data ingested and retrieved. Provision is the number of shards and data transfer for capacity. For right, you have 200 megabits per second for on demand and 200,000 records per second. And for read, you have 400 megabits per second per consumer, you have two consumers by default, if you need more, you can use an enhanced fan out to add 20 more consumers for provision, you have one megabits per second per shard. And for reads, sorry, for writes, you still you have 1000 records per second per shard. For read, you have two megabits per second per shard and a max max of 200 charts. So if you look at the maximum capacity provision, it's the it's the same as on demand, it's maximum capacity as well. The only difference between choosing on demand is that they're managing the shards underneath. I'm not I guess the thing is that managing the shards yourself is going to be more cost effective. So that's usually the reason why you go with provision. What's interesting is you can switch between capacity modes at any given time, I didn't test this out. So I don't know what that experience is like. But they say in the docs, you can switch between them, which is very interesting to me. On Demand kind of competes with data firehose because they have a similar kind of offering, though data firehose is very simple, and has less customization. So if you need something that is simpler, you and you just want to have some basic transformations and deliver data to very specific end of services, that's going to make more sense to use firehose. And can be used with kinesis data streams and often is to send it to specific data services. So don't think that you have to implement your own custom producers, you can just send it to firehose and then store it somewhere. But maybe if you're trying to save money, there could be reasons as to why you might want to implement your own producers. Let's talk about producers and consumers because they're