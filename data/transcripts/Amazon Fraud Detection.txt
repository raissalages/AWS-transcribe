 Amazon fraud detector is a fully managed fraud detection as a service. It can identify potentially fraudulent online activities such as online payment fraud in the creation of fake accounts. Amazon fraud detector comes with the following predefined models which you'll train your data again. So we have the online fraud insight, which is optimized to detect fraud, when little historical data is available about the entity being evaluated, for example, a new customer registering online for a new account, transactional fraud insights. So testing fraud use cases where the entity that is being evaluated might have a historical a history of interactions, the model can analyze improved prediction accuracy, account takeover insights. So if an account was compromised by phishing or another type of type of attack, the primary way you're going to work with this is using the SDK and utilizing the SDK, you can create yourself a real time fraud detection system. So what makes this real time is when you integrate it with other services, such as a step functions, kinesis, lambda. And you have to understand these AI services, especially with exam questions. And this goes for any of the exams is that they're less focused on knowing exactly how to work with these services and knowing how they can integrate and be worked, worked in the architecture stuff. So always have in the back mind, services that can be utilized, and most of the AI services can be connected with lambda and brought with application integration. So you're going to upload your data set into s3 bucket and then referenced by fraud detector. Again, a lot of services expect you to put them into s3 and then reference them. So that is not unusual. Here's an example of us creating a model. So we're choosing the model type. In this case, we're doing online fraud insights. I don't know I didn't animate the bullet points here, but I'll just highlight here. So online fraud insights. Then we're choosing our data source, which is defined here as s3. But I didn't see any other type of data source we could utilize. We're defining the label mapping, and we're defining the model variables here. Okay. After we review our model performance, we set it to active to deploy our model for real time detection. There's a lot of components here for fraud detector. So I have this little visualization, because there's a lot of things that you have to define. So like your model threshold rules and outcomes, rules interpret variable values during a fraud prediction, you have either variables or lists of variables to operate on, you have to define expressions, maybe with regular expressions, and then you'll say what outcome you want to occur. There are scores, which are numerical values that represent the estimated risk level of a given event. Being fraudulent, different models use different scoring. So understand that you have your outcomes, which define the fraud prediction results. So that could be risk levels or actions, you can define whatever you want for your outcomes. To create a model, you need to define events, which need labels, identities and variables. So entities represent who is performing the event. Labels are classifies an event is fraudulent or legitimate variables, or data points used in your model such as location transaction, transaction amount, and that double m should not be there. Events are containing the data and rules that will be analyzed by the model. So, you know, just understand that you can integrate with this with application integration and what it does, okay. Amazon can