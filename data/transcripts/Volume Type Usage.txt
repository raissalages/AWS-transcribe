 All right, let's take a look here at volume type usage. First, we'll compare the solid state drives and then the hard disk drives. So the first thing is we have volume types GP two GP three IO one IO two block express, we're gonna pretend like IO two does not exist because you should not use it anymore. Let's look at the use case for general purpose, both general workloads, transactional workloads, virtual desktops, medium sized, single instance services, low latency interactive apps, volumes and development and test environments when you don't know what to choose to the general purpose volumes such as GP two or GP three. Sometimes people just use GP two because the free tier is on GP two as opposed to GP three. But if you're going to run something, I'd run it on GP three, because we're not in the free tier GP three is going to be more cost effective. Anyway, we have IO one so workloads that requires sustained I ops performance of more than 16 I ops through IO intensive database workloads for IO two block express. These are sub millisecond latency, sustained I ops performance more than 64,000 I ops or 1000 megabits per second of throughput. So just remember the 16,000 to 64,000 that's going to help you choose the volume because exams might ask you to choose the correct volume. For durability, we have 98 99.8% to 99.9%. For IO two, it's the same. And for IO block express, it just happens to be 99.999%. The volume size is between one to 16 terabytes for GPT two and GPT three. For IO two, it's four gigabytes between 16 plus it's gigabits. We see the eyes gigabits. So it's four gigabits between 16 terabits. And the last one is four gigabits between 64 terabits. So a lot of storage for IO two block express. The next I ops here is 16,000. This one 64,000. This one's 256,000. Remember those values that is important. Max throughput is 250 megabits per second for GPT to 1000 megabits per second for GPT three. For IO one, we have 1000 megabits for IO two block express, we have 4000 megabits, we can not attach EBS multi attached for general purpose, but we can for I ops provisioned SSD, there is no NV NVM, he reservation, you can't reserve MBMs. But for IO two block express, you absolutely can. That doesn't mean you can't use MBM with other ones. It's just in particular, it's about reservation. For boot volume, they can all be used for boot volume. Let's take a look at the hard disk drives, we have throughput optimized cold and magnetic ST one SC one and standard big data data warehouses, log processing for ST one for cold, it's going to be throughput oriented storage for data that is infrequently accessed, where both storage costs is important. And then magnetic is workloads where data is accessed infrequently. Magnet is going to be the cheapest at volume. Right? For durability, we have 99.8 to 99.9%. We don't talk about durability here because it's it's not represented in the same way. But if you want to think about durability, these magnetic tapes are good for 30 years. So there's not gonna be an issue here. It says infrequently access, but really, like the last one is more like, you never access unless you're really like really infrequent. Because it's super cold storage, right? Volume size here 120 125 gigabits between 16 terabits. Here it's between one gigabit and one terabit. We have 500 500 for the max I ops here, it's 250, then 40 to 200. Next throughput is 500 megabits to 50 megabits and then 40 90 megabits cannot do EBS multi attach here. Not available for magnetic because it doesn't make any sense. For boot volume. Nope. For magnetic it is supported. Okay, so there you go.