 a look here at Amazon Polly, which is a text to speech service, you upload your text and an audio file will be produced with the synthesized voice. There are three different engine types, we have standard long form and neural. For standard, it's not the most natural sounding, but it's extremely cost effective long form. It sounds a bit better. And then neural is the best. Specifically, they say it has this newscaster speaking style that you can utilize, I think you have to tell it to do that if you want that. But basically neural is the best sounding one. But of course, it is more expensive. There is a variation between voices depending on the text being spoke. So there is no standard speed of or words per minute. Basically, the speed at which the person talks to is the speed that they go at the way it works is you can call it using like a CLI call here. So here you can see I'm using the engine neural, I want an mp3 as the output format, I'm assuming the other format might be augur wave, I don't remember is just taking things as mp3. There is a lexicon. So if you need specific pronunciations of words, you can upload a lexicon file and tell it how to speak properly. There are speech marks, which is metadata to describe the speech, this is going to manipulate how the speech speech works. There's examples for where word starts or ends, you can use SS ml, which we'll look at in a moment here. You can also integrate it with this me I'm not sure why it has integration with this particular third party service. But the third party service produces marketing materials, and somehow integrates with it. And so use speech marks to connect the two. Here's an example of the speech synthesis markup language, which is an XML based markup language. And you can see that is doing things here. So getting my pen tool out, it's creating a break of one second. I'm not sure I guess it's saying this is w3c. So to actually say that instead, so substituting there are Amazon specific ones. So like there is the base, the base markup language that is universal to most synthesis, synthetic or synthesized voices. But here you can see that Amazon has added their own tags. So we have a whisper. Let's take a quick look at what as this ml tags are supported. So we have speak, break, emphasis, Lang, Mark, paragraph, fondaman fondaman mean, I can't pronounce that prosody, which is for controlling volume, speaking rate and pitch. So I guess you could speed up the voice a bit, but you're not going to have a consistent one between voices still pauses between sentences, totally how special types of words are spoken, acronyms or abbreviations, improving pronunciation by specifying parts of the word, adding breaths, that's Amazon specific, adding the newscasters speaking style, which is only for neural, adding dynamic range compression, speaking softly, controlling timber whispering, obviously, the ones on the end are Amazon specific, different engine types will support different tags. So I'm showing all of them here. But you're going to find it's going to completely vary depending on what you're doing. But there you go. Hey,